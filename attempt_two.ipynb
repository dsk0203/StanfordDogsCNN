{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Dogs CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic modeling\n",
    "import os\n",
    "import torch\n",
    "#import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for reading and displaying images and editing\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# validation & test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loss Function & Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data Cleaning\n",
    "#from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable # requires_gradient = true\n",
    "from torch.nn import Linear, ReLU, Sequential, Conv2d, MaxPool2d, Module\n",
    "from torch.nn import Softmax, BatchNorm2d, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n02085620-Chihuahua', 'n02085782-Japanese_spaniel', 'n02085936-Maltese_dog', 'n02086079-Pekinese', 'n02086240-Shih-Tzu', 'n02086646-Blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-Rhodesian_ridgeback', 'n02088094-Afghan_hound', 'n02088238-basset', 'n02088364-beagle', 'n02088466-bloodhound', 'n02088632-bluetick', 'n02089078-black-and-tan_coonhound', 'n02089867-Walker_hound', 'n02089973-English_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-Irish_wolfhound', 'n02091032-Italian_greyhound', 'n02091134-whippet', 'n02091244-Ibizan_hound', 'n02091467-Norwegian_elkhound', 'n02091635-otterhound', 'n02091831-Saluki', 'n02092002-Scottish_deerhound', 'n02092339-Weimaraner', 'n02093256-Staffordshire_bullterrier', 'n02093428-American_Staffordshire_terrier', 'n02093647-Bedlington_terrier', 'n02093754-Border_terrier', 'n02093859-Kerry_blue_terrier', 'n02093991-Irish_terrier', 'n02094114-Norfolk_terrier', 'n02094258-Norwich_terrier', 'n02094433-Yorkshire_terrier', 'n02095314-wire-haired_fox_terrier', 'n02095570-Lakeland_terrier', 'n02095889-Sealyham_terrier', 'n02096051-Airedale', 'n02096177-cairn', 'n02096294-Australian_terrier', 'n02096437-Dandie_Dinmont', 'n02096585-Boston_bull', 'n02097047-miniature_schnauzer', 'n02097130-giant_schnauzer', 'n02097209-standard_schnauzer', 'n02097298-Scotch_terrier', 'n02097474-Tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-West_Highland_white_terrier', 'n02098413-Lhasa', 'n02099267-flat-coated_retriever', 'n02099429-curly-coated_retriever', 'n02099601-golden_retriever', 'n02099712-Labrador_retriever', 'n02099849-Chesapeake_Bay_retriever', 'n02100236-German_short-haired_pointer', 'n02100583-vizsla', 'n02100735-English_setter', 'n02100877-Irish_setter', 'n02101006-Gordon_setter', 'n02101388-Brittany_spaniel', 'n02101556-clumber', 'n02102040-English_springer', 'n02102177-Welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-Sussex_spaniel', 'n02102973-Irish_water_spaniel', 'n02104029-kuvasz', 'n02104365-schipperke', 'n02105056-groenendael', 'n02105162-malinois', 'n02105251-briard', 'n02105412-kelpie', 'n02105505-komondor', 'n02105641-Old_English_sheepdog', 'n02105855-Shetland_sheepdog', 'n02106030-collie', 'n02106166-Border_collie', 'n02106382-Bouvier_des_Flandres', 'n02106550-Rottweiler', 'n02106662-German_shepherd', 'n02107142-Doberman', 'n02107312-miniature_pinscher', 'n02107574-Greater_Swiss_Mountain_dog', 'n02107683-Bernese_mountain_dog', 'n02107908-Appenzeller', 'n02108000-EntleBucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-Tibetan_mastiff', 'n02108915-French_bulldog', 'n02109047-Great_Dane', 'n02109525-Saint_Bernard', 'n02109961-Eskimo_dog', 'n02110063-malamute', 'n02110185-Siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-Leonberg', 'n02111277-Newfoundland', 'n02111500-Great_Pyrenees', 'n02111889-Samoyed', 'n02112018-Pomeranian', 'n02112137-chow', 'n02112350-keeshond', 'n02112706-Brabancon_griffon', 'n02113023-Pembroke', 'n02113186-Cardigan', 'n02113624-toy_poodle', 'n02113712-miniature_poodle', 'n02113799-standard_poodle', 'n02113978-Mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-African_hunting_dog']\n"
     ]
    }
   ],
   "source": [
    "# Directory where data is\n",
    "#laptop\n",
    "#data_dir = r'C:\\Users\\dsk02\\Desktop\\python_projects\\torch_dogs\\main_images\\Images'\n",
    "\n",
    "#gpu comp\n",
    "data_dir = r'C:\\Users\\Dylan\\Desktop\\GPU_RUN\\StanfordDogsCNN\\images\\Images'\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 120/120 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chihuahua', 'japanese_spaniel', 'maltese_dog', 'pekinese', 'shih tzu', 'blenheim_spaniel', 'papillon', 'toy_terrier', 'rhodesian_ridgeback', 'afghan_hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black and tan_coonhound']\n"
     ]
    }
   ],
   "source": [
    "# clean up classes name\n",
    "temp = os.listdir(data_dir)\n",
    "\n",
    "classes = []\n",
    "\n",
    "# class cleaning\n",
    "\n",
    "for each_folder in tqdm(temp):\n",
    "    \n",
    "    # split words on -\n",
    "    split_words = each_folder.split('-')\n",
    "    \n",
    "    # if there is more than one dash\n",
    "    if len(split_words) > 2:\n",
    "        \n",
    "        # create temp word\n",
    "        temp = ''\n",
    "        # for each value in the split_words array (starting from 1)\n",
    "        for i in range(1,len(split_words)):\n",
    "            \n",
    "            # if it's not the end add word + space\n",
    "            if i != (len(split_words)-1):\n",
    "                temp += (split_words[i] + ' ')\n",
    "            else:\n",
    "                # if end just add the word\n",
    "                temp += (split_words[i])\n",
    "        \n",
    "        # append temp to classes\n",
    "        classes.append(temp.lower())\n",
    "    \n",
    "    # if it equals 2 it's just nasty title + name, append name\n",
    "    elif len(split_words) == 2:\n",
    "        classes.append(each_folder.split('-')[1].lower())\n",
    "    \n",
    "    # outliers append \n",
    "    else:\n",
    "        classes.append(each_folder.lower())\n",
    "    \n",
    "# print first few classes, all lower case\n",
    "print(classes[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'str'>, {0: 'chihuahua', 1: 'japanese_spaniel', 2: 'maltese_dog', 3: 'pekinese', 4: 'shih tzu', 5: 'blenheim_spaniel', 6: 'papillon', 7: 'toy_terrier', 8: 'rhodesian_ridgeback', 9: 'afghan_hound', 10: 'basset', 11: 'beagle', 12: 'bloodhound', 13: 'bluetick', 14: 'black and tan_coonhound', 15: 'walker_hound', 16: 'english_foxhound', 17: 'redbone', 18: 'borzoi', 19: 'irish_wolfhound', 20: 'italian_greyhound', 21: 'whippet', 22: 'ibizan_hound', 23: 'norwegian_elkhound', 24: 'otterhound', 25: 'saluki', 26: 'scottish_deerhound', 27: 'weimaraner', 28: 'staffordshire_bullterrier', 29: 'american_staffordshire_terrier', 30: 'bedlington_terrier', 31: 'border_terrier', 32: 'kerry_blue_terrier', 33: 'irish_terrier', 34: 'norfolk_terrier', 35: 'norwich_terrier', 36: 'yorkshire_terrier', 37: 'wire haired_fox_terrier', 38: 'lakeland_terrier', 39: 'sealyham_terrier', 40: 'airedale', 41: 'cairn', 42: 'australian_terrier', 43: 'dandie_dinmont', 44: 'boston_bull', 45: 'miniature_schnauzer', 46: 'giant_schnauzer', 47: 'standard_schnauzer', 48: 'scotch_terrier', 49: 'tibetan_terrier', 50: 'silky_terrier', 51: 'soft coated_wheaten_terrier', 52: 'west_highland_white_terrier', 53: 'lhasa', 54: 'flat coated_retriever', 55: 'curly coated_retriever', 56: 'golden_retriever', 57: 'labrador_retriever', 58: 'chesapeake_bay_retriever', 59: 'german_short haired_pointer', 60: 'vizsla', 61: 'english_setter', 62: 'irish_setter', 63: 'gordon_setter', 64: 'brittany_spaniel', 65: 'clumber', 66: 'english_springer', 67: 'welsh_springer_spaniel', 68: 'cocker_spaniel', 69: 'sussex_spaniel', 70: 'irish_water_spaniel', 71: 'kuvasz', 72: 'schipperke', 73: 'groenendael', 74: 'malinois', 75: 'briard', 76: 'kelpie', 77: 'komondor', 78: 'old_english_sheepdog', 79: 'shetland_sheepdog', 80: 'collie', 81: 'border_collie', 82: 'bouvier_des_flandres', 83: 'rottweiler', 84: 'german_shepherd', 85: 'doberman', 86: 'miniature_pinscher', 87: 'greater_swiss_mountain_dog', 88: 'bernese_mountain_dog', 89: 'appenzeller', 90: 'entlebucher', 91: 'boxer', 92: 'bull_mastiff', 93: 'tibetan_mastiff', 94: 'french_bulldog', 95: 'great_dane', 96: 'saint_bernard', 97: 'eskimo_dog', 98: 'malamute', 99: 'siberian_husky', 100: 'affenpinscher', 101: 'basenji', 102: 'pug', 103: 'leonberg', 104: 'newfoundland', 105: 'great_pyrenees', 106: 'samoyed', 107: 'pomeranian', 108: 'chow', 109: 'keeshond', 110: 'brabancon_griffon', 111: 'pembroke', 112: 'cardigan', 113: 'toy_poodle', 114: 'miniature_poodle', 115: 'standard_poodle', 116: 'mexican_hairless', 117: 'dingo', 118: 'dhole', 119: 'african_hunting_dog'})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# create lookup dictionary for index -> class\n",
    "lookup = [x for x in range(0,len(classes))]\n",
    "\n",
    "# initialize with strings\n",
    "classLookup = defaultdict(str)\n",
    "\n",
    "# index and class, push into defaultDict ->\n",
    "for i, each_class in enumerate(classes):\n",
    "    classLookup[i] = each_class\n",
    "    \n",
    "# will use at end for lookups on guesses\n",
    "print(classLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 120\n",
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:09, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load train images\n",
    "train_img = []\n",
    "train_targets = []\n",
    "\n",
    "def load_train(): \n",
    "\n",
    "    temp = os.listdir(data_dir)\n",
    "\n",
    "    # for each folder in the train set\n",
    "    for i_, each_folder in tqdm(enumerate(temp)):\n",
    "\n",
    "        print('{} out of {}'.format(i_, len(temp)))\n",
    "\n",
    "        #current image names\n",
    "        image_names = os.listdir(data_dir + '/' + str(temp[i_]))\n",
    "\n",
    "        # for each file in the folder \n",
    "        for i, img_name in enumerate(image_names):\n",
    "\n",
    "            # image path\n",
    "            image_path = str(str(data_dir) + '/' + str(temp[i_]) + '/' + str(img_name))\n",
    "\n",
    "            #read image\n",
    "            img = imread(image_path)\n",
    "\n",
    "            #change image shape to -> 3,28,28 (originally were massive)\n",
    "            img = resize(img, (3,28,28))\n",
    "\n",
    "            # convert dt -> may have to change if 2 big\n",
    "            img = img.astype('float32')\n",
    "\n",
    "            #append to trainning list\n",
    "            train_img.append(img)\n",
    "\n",
    "            #append to targets list\n",
    "            train_targets.append(i)\n",
    "            \n",
    "            # delete this\n",
    "            if i == 70:\n",
    "                print(i)\n",
    "                return 0\n",
    "\n",
    "load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy arrays, make sure worked also\n",
    "print(len(train_img))\n",
    "print(len(train_targets))\n",
    "\n",
    "train_x = np.array(train_img)\n",
    "train_y = np.array(train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating validation set and preprocessing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, \n",
    "                                                train_y, \n",
    "                                                test_size = 0.1,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 3, 28, 28)\n",
      "(63,)\n",
      "(8, 3, 28, 28)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 3, 28, 28]) torch.Size([63])\n",
      "torch.Size([8, 3, 28, 28]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "train_xT = torch.from_numpy(train_x)\n",
    "train_yT = torch.from_numpy(train_y)\n",
    "train_yT = train_yT.long()\n",
    "\n",
    "print(train_xT.shape, train_yT.shape)\n",
    "\n",
    "val_xT = torch.from_numpy(val_x)\n",
    "val_yT = torch.from_numpy(val_y)\n",
    "val_yT = val_yT.long()\n",
    "\n",
    "print(val_xT.shape, val_yT.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class StanfordDogs(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_layers = Sequential(\n",
    "            Conv2d(3,32, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(32),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            Conv2d(32,64, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(2, 2) # 64 x 14 x 14   \n",
    "        )\n",
    "        \n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(64 * 14 * 14, len(classes)))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Modeling / GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available \n",
      "\n",
      "StanfordDogs(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=12544, out_features=120, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "model = StanfordDogs()\n",
    "\n",
    "# optimizer, Adam GOAT\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# if gpu -> Cuda\n",
    "if torch.cuda.is_available():\n",
    "    # push to gpu\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    print('GPU is available \\n')\n",
    "else:\n",
    "    print('GPU is not available \\n')\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_Tracker = []\n",
    "\n",
    "def train(epoch):\n",
    "    \n",
    "    # tell model that trainning is coming\n",
    "    model.train()\n",
    "    \n",
    "    # loss\n",
    "    loss = 0\n",
    "    \n",
    "    # get trainning set\n",
    "    x_train, y_train = Variable(train_xT), Variable(train_yT) # req_grad = Tru\n",
    "    \n",
    "    # get validation set\n",
    "    x_val, y_val = Variable(val_xT), Variable(val_yT)\n",
    "    \n",
    "    # check gpu, if so -> send\n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "        \n",
    "    \n",
    "    #clear gradients of model params\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #preds\n",
    "    train_preds = model(x_train)\n",
    "    val_preds = model(x_val)\n",
    "    \n",
    "    # loss\n",
    "    train_loss = criterion(train_preds, y_train)\n",
    "    loss_val = criterion(val_preds, y_val)\n",
    "    \n",
    "    # keep track of val set loss, want to graph\n",
    "    loss_Tracker.append(loss_val)\n",
    "    \n",
    "    # update weights\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # extract float\n",
    "    loss = loss_val.item()\n",
    "    print('Epoch : {}, Loss {}.'.format(epoch+1,loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                    | 1/25 [00:00<00:14,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss 224.33897399902344.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███                                   | 2/25 [00:01<00:11,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Loss 216.2875213623047.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▌                                 | 3/25 [00:01<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Loss 209.3113555908203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████                                | 4/25 [00:01<00:09,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Loss 203.17184448242188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████▌                              | 5/25 [00:02<00:07,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Loss 197.75917053222656.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|█████████                             | 6/25 [00:02<00:06,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Loss 193.00613403320312.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████▋                           | 7/25 [00:02<00:05,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Loss 188.8110809326172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|████████████▏                         | 8/25 [00:02<00:04,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Loss 185.02732849121094.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████▋                        | 9/25 [00:03<00:04,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Loss 181.6373291015625.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████▊                      | 10/25 [00:03<00:03,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Loss 178.63388061523438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████▎                    | 11/25 [00:03<00:03,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11, Loss 175.9929962158203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|█████████████████▊                   | 12/25 [00:03<00:03,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12, Loss 173.68231201171875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|███████████████████▏                 | 13/25 [00:04<00:02,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13, Loss 171.66152954101562.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████▋                | 14/25 [00:04<00:02,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14, Loss 169.9087371826172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████▏              | 15/25 [00:04<00:02,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15, Loss 168.3998260498047.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████▋             | 16/25 [00:04<00:02,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16, Loss 167.11131286621094.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|█████████████████████████▏           | 17/25 [00:05<00:02,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17, Loss 166.02102661132812.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████▋          | 18/25 [00:05<00:02,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18, Loss 165.11412048339844.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████         | 19/25 [00:06<00:02,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19, Loss 164.36875915527344.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████▌       | 20/25 [00:06<00:02,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20, Loss 163.76512145996094.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████      | 21/25 [00:07<00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21, Loss 163.28692626953125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████▌    | 22/25 [00:07<00:01,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22, Loss 162.91744995117188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|██████████████████████████████████   | 23/25 [00:08<00:01,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23, Loss 162.64024353027344.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|███████████████████████████████████▌ | 24/25 [00:09<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24, Loss 162.4394989013672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 25/25 [00:09<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25, Loss 162.30213928222656.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Running\n",
    "epochs = 25\n",
    "for epoch in tqdm(range(0,epochs)):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
